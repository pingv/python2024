{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "# see: https://smith.langchain.com/onboarding?organizationId=d2049340-4608-4461-ace9-b8318e01e696&step=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using Language Models </h1>\n",
    "<h3> OpenAI </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "## see: https://platform.openai.com/settings/profile?tab=api-keys\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='காதல் இறைவன்! இறைவன் மிகப் பெரியவர்!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 26, 'total_tokens': 41, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None}, id='run-207fe49f-86e4-40cc-8c75-c465878e639e-0', usage_metadata={'input_tokens': 26, 'output_tokens': 15, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Tamil\"),\n",
    "    HumanMessage(content=\"Love is God! God is Great!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> OutputParsers - How to parse the response from OpenAI into a much simpler user readable format </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'காதல் கடவுள்! கடவுள் பெரியவர்!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "result = model.invoke(messages)\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'காதல் கடவுள்! கடவுள் மகிமை!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = model | parser\n",
    "chain.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using Templates for Prompt </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'இனிய இரவு! நான் உறங்க போகிறேன்.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following into {what_language}:\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{user_input}\")]\n",
    ")\n",
    "\n",
    "result = prompt_template.invoke({\"what_language\": \"tamil\", \"user_input\": \"Good morning! How are you doing?\"})\n",
    "# result\n",
    "result.to_messages()\n",
    "\n",
    "# result = model.invoke(result)\n",
    "\n",
    "# parser = StrOutputParser()\n",
    "# parser.invoke(result)\n",
    "\n",
    "chain = prompt_template | model | parser\n",
    "chain.invoke({\"what_language\": \"tamil\", \"user_input\": \"Good Night! I am going to sleep\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Serving with LangServe </h1>\n",
    "<h4> Seems like a Tomcat / Jetty server </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install \"langserve[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Interacting with the server app </h4>\n",
    "<h5> Similar to a CLUI Access maybe!? </h5>\n",
    "Web Access through http://localhost:8000/chain/playground/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buenos días, Buenas tardes, Buenas noches.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/chain/\")\n",
    "remote_chain.invoke({\"language\": \"Spanish\", \"text\": \"Good morning, Good Evening, Good Night\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Building a LLM Application from Greg Kamradt YT channel </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/1p59mfqd3y1dhh7_w0y789h00000gn/T/ipykernel_32791/967748239.py:6: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm(text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "1. Los Angeles: Known for its sunny weather, famous landmarks like Hollywood Boulevard and Venice Beach, and a thriving entertainment industry, Los Angeles offers a diverse range of activities for tourists.\n",
      "\n",
      "2. San Francisco: With its iconic Golden Gate Bridge, charming neighborhoods, and world-renowned food scene, San Francisco is a must-see destination in California.\n",
      "\n",
      "3. San Diego: With its beautiful beaches, mild weather, and family-friendly attractions like the San Diego Zoo and SeaWorld, San Diego is a top vacation spot for all ages.\n",
      "\n",
      "4. Napa Valley: For wine lovers, Napa Valley offers stunning scenery, world-class wineries, and luxury accommodations for a relaxing and indulgent vacation.\n",
      "\n",
      "5. Yosemite National Park: For outdoor enthusiasts, Yosemite National Park is a must-visit destination in California. With its breathtaking landscapes, hiking trails, and camping opportunities, it's a great spot for nature lovers to explore and unwind.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "text = \"What are the top 5 vacation spots in California\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
